{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing the module you want to import\n",
    "tpm_directory = '/Users/priyadcosta/Documents/GitHub/coefficientofconflict/team-process-map/feature_engine'\n",
    "\n",
    "# Add the directory to sys.path\n",
    "sys.path.append(tpm_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Basic Pre-processing\n",
    "\n",
    "Converting the labels to numbers and averaging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/priyadcosta/Documents/GitHub/coefficientofconflict/tpm-data-anotation/CONFLICT_CONVO_LABELING_LOG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert the labels into numeric scores\n",
    "\"\"\"\n",
    "\n",
    "def get_numeric_labels(text):\n",
    "\n",
    "    # Convert the text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize the result variable\n",
    "    result = 0\n",
    "    \n",
    "    # Check if \"yes\" is present in the text\n",
    "    if 'yes' in text_lower:\n",
    "        result = 1\n",
    "    elif 'no' in text_lower:\n",
    "        result = 0\n",
    "    \n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "Convert all the columns to numeric labels\n",
    "\"\"\"\n",
    "def convert_labels(df):\n",
    "    \n",
    "    df['d_content'] = df['rating_directness_content'].apply(get_numeric_labels)\n",
    "    df['d_expression'] = df['rating_directness_expression'].apply(get_numeric_labels)\n",
    "    df['oi_content'] = df['rating_OI_content'].apply(get_numeric_labels)\n",
    "    df['oi_expression'] = df['rating_OI_expression'].apply(get_numeric_labels)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Get the average of the ratings for a single column\n",
    "\"\"\"\n",
    "def get_averages(df,on_column):\n",
    "\n",
    "    # Calculate average ratings\n",
    "    average_ratings = df.groupby(['CONV_ID', 'id'])[on_column].mean().reset_index()\n",
    "\n",
    "    # Merge average ratings with original DataFrame\n",
    "    df = df.merge(average_ratings, on=['CONV_ID', 'id'], how='left', suffixes=('', '_average'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Get the average ratings for all the columns\n",
    "\"\"\"\n",
    "def average_labels(df, columns):\n",
    "    for column in columns:\n",
    "        df = get_averages(df, column)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determine the labels for the dataset\n",
    "\"\"\"\n",
    "def get_label(conv_id):\n",
    "    if conv_id.endswith('_A') or conv_id.endswith('_B'):\n",
    "        return 'winning'\n",
    "    else:\n",
    "        return 'awry'\n",
    "\n",
    "\"\"\" \n",
    "Get the dataset which the conversation belongs to awry or winning\n",
    "\"\"\"\n",
    "def dataset_labels(df):\n",
    "    df['dataset'] = df['CONV_ID'].apply(get_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Drop unncessary columns \n",
    "\"\"\"\n",
    "def drop_cols(df,type):\n",
    "    if type == 'average':\n",
    "        return df[['d_content_average', 'd_expression_average', 'oi_content_average','oi_expression_average', 'dataset']]\n",
    "    else:\n",
    "        return df[['d_content', 'd_expression', 'oi_content','oi_expression','dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset to which the chat belongs\n",
    "dataset_labels(data)\n",
    "\n",
    "#convert the text labels to numeric labels\n",
    "convert_labels(data)\n",
    "\n",
    "#get the average rating for each chat\n",
    "numeric_cols = ['d_content', 'd_expression', 'oi_content', 'oi_expression']\n",
    "data = average_labels(data,numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awry convos 32\n",
      "winning convos 26\n"
     ]
    }
   ],
   "source": [
    "print('awry convos ' + str(data[data['dataset'] == 'awry']['CONV_ID'].nunique()))\n",
    "print('winning convos ' + str(data[data['dataset'] == 'winning']['CONV_ID'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data = drop_cols(data,'average')\n",
    "original_data = drop_cols(data,'original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_logistic_regression(df,target_column):\n",
    "\n",
    "    # Split features and target\n",
    "    X = df.drop(target_column, axis=1)  # Features\n",
    "    y = df[target_column]   \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19104)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Assuming you have already trained a logistic regression model named 'model'\n",
    "    # and 'X_train' is your feature matrix\n",
    "\n",
    "    # Get the coefficients (weights) of the logistic regression model\n",
    "    coefficients = model.coef_[0]\n",
    "\n",
    "    # Get the names of the features\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    # Create a DataFrame to store the coefficients and feature names\n",
    "    coefficients_df = pd.DataFrame({'Feature': feature_names, 'Weights': coefficients})\n",
    "\n",
    "    # Sort the DataFrame by coefficient magnitude (absolute value) to identify the most predictive features\n",
    "    coefficients_df = coefficients_df.sort_values(by='Weights', ascending=False)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(coefficients_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6490066225165563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        awry       0.66      0.97      0.79       201\n",
      "     winning       0.14      0.01      0.02       101\n",
      "\n",
      "    accuracy                           0.65       302\n",
      "   macro avg       0.40      0.49      0.40       302\n",
      "weighted avg       0.49      0.65      0.53       302\n",
      "\n",
      "                 Feature   Weights\n",
      "1   d_expression_average  2.155936\n",
      "0      d_content_average -1.463885\n",
      "2     oi_content_average -1.547637\n",
      "3  oi_expression_average -1.766148\n"
     ]
    }
   ],
   "source": [
    "run_logistic_regression(avg_data,'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.652317880794702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        awry       0.66      0.98      0.79       201\n",
      "     winning       0.00      0.00      0.00       101\n",
      "\n",
      "    accuracy                           0.65       302\n",
      "   macro avg       0.33      0.49      0.39       302\n",
      "weighted avg       0.44      0.65      0.53       302\n",
      "\n",
      "         Feature   Weights\n",
      "1   d_expression  1.277079\n",
      "2     oi_content -1.014712\n",
      "3  oi_expression -1.149079\n",
      "0      d_content -1.226290\n"
     ]
    }
   ],
   "source": [
    "run_logistic_regression(original_data,'dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_numeric_labels(text):\n",
    "\n",
    "    # Convert the text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Initialize the result variable\n",
    "    result = 0\n",
    "    \n",
    "    # Check if \"yes\" is present in the text\n",
    "    if 'winning' in text_lower:\n",
    "        result = 1\n",
    "    elif 'awry' in text_lower:\n",
    "        result = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8j/rzq1_zj938vgp1cqknfrmc0m0000gn/T/ipykernel_20509/2433585705.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  avg_data['dataset_numeric'] = avg_data['dataset'].apply(get_dataset_numeric_labels)\n"
     ]
    }
   ],
   "source": [
    "#convert the dataset labels to numbers. winning = 1, awry = 0\n",
    "avg_data['dataset_numeric'] = avg_data['dataset'].apply(get_dataset_numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CONV_ID', 'id', 'rating_directness_content',\n",
       "       'rating_directness_expression', 'rating_OI_content',\n",
       "       'rating_OI_expression', 'rater_id', 'status', 'last_updated_time',\n",
       "       'dataset', 'd_content', 'd_expression', 'oi_content', 'oi_expression',\n",
       "       'd_content_average', 'd_expression_average', 'oi_content_average',\n",
       "       'oi_expression_average'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 64)   # Input size: 4, Output size: 64\n",
    "        self.fc2 = nn.Linear(64, 32)  # Input size: 64, Output size: 32\n",
    "        self.fc3 = nn.Linear(32, 1)   # Input size: 32, Output size: 1\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "def neural_net(df):\n",
    "\n",
    "    # Select features and target variable\n",
    "    X = df[['d_content_average', 'd_expression_average', 'oi_content_average', 'oi_expression_average']]\n",
    "    y = df['dataset_numeric']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19104)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)  # Reshape to (batch_size, 1)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # Create an instance of the model\n",
    "    model = NeuralNetwork()\n",
    "\n",
    "    # Define the loss function and optimizer - Most popularly used\n",
    "    criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)  # AdamW optimizer with weight decay\n",
    "\n",
    "    #TensorDataset: This class is used to wrap tensors representing the input features and target labels into a single dataset object. Each sample in the dataset corresponds to a pair of input features and target labels.\n",
    "    #DataLoader: This class is used to create an iterable over the dataset, enabling you to iterate through batches of data during training. It allows you to specify parameters such as batch size and whether to shuffle the data between epochs.\n",
    "    \n",
    "    # Convert data to DataLoader\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Training the model\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = model(X_test_tensor)\n",
    "        predictions = (outputs >= 0.5).float()  # Thresholding at 0.5\n",
    "        \n",
    "        # Convert PyTorch tensors to numpy arrays with float32 data type\n",
    "        predictions_np = predictions.numpy().astype('float32')\n",
    "        y_test_np = y_test_tensor.numpy().astype('float32')\n",
    "        \n",
    "        # Calculate precision, recall, and F1 score for each label\n",
    "        precision_per_label = precision_score(y_test_np, predictions_np, average=None)\n",
    "        recall_per_label = recall_score(y_test_np, predictions_np, average=None)\n",
    "        f1_per_label = f1_score(y_test_np, predictions_np, average=None)\n",
    "        \n",
    "        # Print precision, recall, and F1 score for each label\n",
    "        for i in range(len(precision_per_label)):\n",
    "            print(f'Label {i}: Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1 Score: {f1_per_label[i]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: Precision: 0.6723, Recall: 0.9900, F1 Score: 0.8008\n",
      "Label 1: Precision: 0.6667, Recall: 0.0396, F1 Score: 0.0748\n"
     ]
    }
   ],
   "source": [
    "neural_net(avg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the Recurrent Neural Network (RNN) model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.relu(out[:, -1, :])  # Get output from the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def attention_model(df):\n",
    "    # Select features and target variable\n",
    "    X = df[['d_content_average', 'd_expression_average', 'oi_content_average', 'oi_expression_average']]\n",
    "    y = df['dataset_numeric']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19104)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)  # Reshape to (batch_size, 1)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # Create an instance of the RNN model\n",
    "    model = RNN(X_train_tensor.shape[1], 64)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)  # AdamW optimizer with weight decay\n",
    "\n",
    "    # Convert data to DataLoader\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Training the model\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = model(X_test_tensor)\n",
    "        predictions = (outputs >= 0.5).float()  # Thresholding at 0.5\n",
    "        \n",
    "        # Convert PyTorch tensors to numpy arrays with float32 data type\n",
    "        predictions_np = predictions.numpy().astype('float32')\n",
    "        y_test_np = y_test_tensor.numpy().astype('float32')\n",
    "        \n",
    "        # Calculate precision, recall, and F1 score for each label\n",
    "        precision_per_label = precision_score(y_test_np, predictions_np, average=None)\n",
    "        recall_per_label = recall_score(y_test_np, predictions_np, average=None)\n",
    "        f1_per_label = f1_score(y_test_np, predictions_np, average=None)\n",
    "        \n",
    "        # Print precision, recall, and F1 score for each label\n",
    "        for i in range(len(precision_per_label)):\n",
    "            print(f'Label {i}: Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1 Score: {f1_per_label[i]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mattention_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mavg_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [42], line 69\u001b[0m, in \u001b[0;36mattention_model\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     68\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 69\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     71\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [42], line 26\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Forward propagate LSTM\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# out: tensor of shape (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Decode the hidden state of the last time step\u001b[39;00m\n\u001b[1;32m     29\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Get output from the last time step\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/rnn.py:871\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    869\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    870\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 2-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 871\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    872\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    873\u001b[0m \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "attention_model(avg_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
