{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook contains all the code to pre-process and pickle the inputs for model_1 and model_2 to use\n",
    "\n",
    "#### A new user would run these to generate all the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conflict_utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the complete raw datasets :REPLACE WITH YOUR OWN PATHS!!!\n",
    "winning_df = pd.read_csv('/Users/priyadcosta/Documents/GitHub/coefficientofconflict/tpm-data-anotation/conflict_reddit_data/full_data/winning_conversations.csv')\n",
    "awry_df = pd.read_csv('/Users/priyadcosta/Documents/GitHub/coefficientofconflict/tpm-data-anotation/conflict_reddit_data/full_data/conversations_gone_awry.csv')\n",
    "\n",
    "#Hand labled dataset\n",
    "data = pd.read_csv('/Users/priyadcosta/Documents/GitHub/coefficientofconflict/tpm-data-anotation/CONFLICT_CONVO_LABELING_LOG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataset\n",
    "dataset_labels(data,on_column='CONV_ID')\n",
    "\n",
    "#Drop the Original Post (Only for winning datasets)\n",
    "data = drop_op(data)\n",
    "\n",
    "#Convert the text labels to numeric labels\n",
    "convert_labels(data)\n",
    "\n",
    "#Get the average rating for each chat\n",
    "numeric_cols = ['d_content', 'd_expression', 'oi_content', 'oi_expression']\n",
    "data = average_labels(data,numeric_cols,'CONV_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Human labeled data with text, other data formatted to generate synthetic labels\n",
    "non_hand_labeled, hand_labeled = merge_raw_data(data,winning_df,awry_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format for hand TPM\n",
    "tpm_non_hand_labeled = format_for_tpm(non_hand_labeled)\n",
    "tpm_hand_labeled = format_for_tpm(hand_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generate BERT Embeddings,reduce dimensions and pickle\n",
    "# bert_embeddings_non_hand_labeled = generate_sbert_embeddings(non_hand_labeled,'text',n_components=4)\n",
    "# bert_embeddings_hand_labeled = generate_sbert_embeddings(hand_labeled,'text',n_components=4)\n",
    "\n",
    "# #Pickle the embeddings\n",
    "# pickle_embeddings(bert_embeddings_non_hand_labeled,'embeddings/embeddings_non_hand_labeled.pickle')\n",
    "# pickle_embeddings(bert_embeddings_hand_labeled,'embeddings/embeddings_hand_labeled.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tpm_hand_labeled = drop_op_tpm(tpm_hand_labeled)\n",
    "tpm_non_hand_labeled.to_csv('tpm_non_hand_labeled.csv')\n",
    "tpm_hand_labeled.to_csv('tpm_hand_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../team-process-map/feature_engine')\n",
    "from feature_builder import FeatureBuilder as FeatureBuilder\n",
    "\n",
    "# #Generate TPM features and pickle\n",
    "# feature_builder = FeatureBuilder(\n",
    "#     input_file_path = \"../sandbox/tpm_non_hand_labeled.csv\",\n",
    "#     vector_directory = \"feature_engine_outputs/vector_data/\",\n",
    "#     output_file_path_chat_level = \"tpm_non_hand_labeled_chat_features.csv\",\n",
    "#     output_file_path_user_level = \"tpm_non_hand_labeled_user_labeled.csv\",\n",
    "#     output_file_path_conv_level = \"tpm_non_hand_labeled_conv_labeled.csv\",\n",
    "#     turns = False,\n",
    "# )\n",
    "\n",
    "# feature_builder.featurize(col='text')\n",
    "# tpm_non_hand_labeled = pickle_embeddings(pd.read_csv(\"tpm_non_hand_labeled_chat_features.csv\"),\"embeddings/tpm_non_hand_labeled.pickle\")\n",
    "\n",
    "# feature_builder = FeatureBuilder(\n",
    "#     input_file_path = '../sandbox/tpm_hand_labeled.csv',\n",
    "#     vector_directory = \"feature_engine_outputs/vector_data/\",\n",
    "#     output_file_path_chat_level = \"tpm_hand_labeled_chat_features.csv\",\n",
    "#     output_file_path_user_level = \"tpm_hand_labeled_user_labeled.csv\",\n",
    "#     output_file_path_conv_level = \"tpm_hand_labeled_conv_labeled.csv\",\n",
    "#     turns = False,\n",
    "# )\n",
    "\n",
    "# feature_builder.featurize(col='text')\n",
    "# tpm_hand_labeled = pickle_embeddings(pd.read_csv(\"tpm_chat_awry_features.csv\"),\"embeddings/tpm_hand_labeled.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Chat GPT labels and pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
