{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook contains all the code to pre-process and pickle the inputs for model_1 and model_2 to use\n",
    "\n",
    "#### A new user would run these to generate all the pickle files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### git clone --recurse-submodules https://github.com/PriyaDCosta/coefficientofconflict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conflict_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the complete raw datasets :REPLACE WITH YOUR OWN PATHS!!!\n",
    "winning_df = pd.read_csv('/Users/priyadcosta/Documents/GitHub/coefficientofconflict/tpm-data-anotation/conflict_reddit_data/full_data/winning_conversations.csv')\n",
    "awry_df = pd.read_csv('/Users/priyadcosta/Documents/GitHub/coefficientofconflict/tpm-data-anotation/conflict_reddit_data/full_data/conversations_gone_awry.csv')\n",
    "\n",
    "#Hand labled dataset\n",
    "data = pd.read_csv('/Users/priyadcosta/Documents/GitHub/coefficientofconflict/tpm-data-anotation/CONFLICT_CONVO_LABELING_LOG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataset\n",
    "dataset_labels(data,on_column='CONV_ID')\n",
    "\n",
    "#Convert the text labels to numeric labels\n",
    "convert_labels(data)\n",
    "\n",
    "#Get the average rating for each chat\n",
    "numeric_cols = ['d_content', 'd_expression', 'oi_content', 'oi_expression']\n",
    "data = average_labels(data,numeric_cols,'CONV_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV_ID                                                          d0vwxn6\n",
      "text                   &gt;How are you equating those two?\\n\\nDiversi...\n",
      "speaker                                                  ICouldBeAKiller\n",
      "id                                                               d0whl51\n",
      "timestamp                                                   1457733716.0\n",
      "meta.score                                                           1.0\n",
      "reply_to                                                         d0vyjdq\n",
      "conversation_length                                                    4\n",
      "dataset_numeric                                                        1\n",
      "Name: 61152, dtype: object\n",
      "&gt;How are you equating those two?\n",
      "\n",
      "Diversity means more people. More people equals more children. More children... Younger workforce...\n",
      "Index(['CONV_ID', 'id', 'rating_directness_content',\n",
      "       'rating_directness_expression', 'rating_OI_content',\n",
      "       'rating_OI_expression', 'rater_id', 'status', 'last_updated_time',\n",
      "       'dataset', 'd_content', 'd_expression', 'oi_content', 'oi_expression',\n",
      "       'dataset_numeric', 'd_content_average', 'd_expression_average',\n",
      "       'oi_content_average', 'oi_expression_average', 'text', 'speaker',\n",
      "       'timestamp', 'meta.score', 'reply_to', 'conversation_length',\n",
      "       'human_labels'],\n",
      "      dtype='object')\n",
      "Index(['CONV_ID', 'text', 'speaker', 'id', 'timestamp', 'meta.score',\n",
      "       'reply_to', 'conversation_length', 'dataset_numeric'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Human labeled data with text, other data formatted to generate synthetic labels\n",
    "hand_labeled, non_hand_labeled = merge_raw_data(data,winning_df,awry_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "6851\n"
     ]
    }
   ],
   "source": [
    "#Format for hand TPM\n",
    "tpm_hand_labeled = format_for_tpm(hand_labeled)\n",
    "tpm_non_hand_labeled = format_for_tpm(non_hand_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate BERT Embeddings,reduce dimensions and pickle\n",
    "bert_embeddings_non_hand_labeled = generate_sbert_embeddings(non_hand_labeled,'text',n_components=4)\n",
    "bert_embeddings_hand_labeled = generate_sbert_embeddings(hand_labeled,'text',n_components=4)\n",
    "\n",
    "#Pickle the embeddings\n",
    "pickle_embeddings(bert_embeddings_non_hand_labeled,'embeddings/initial_inputs/embeddings_non_hand_labeled.pickle')\n",
    "pickle_embeddings(bert_embeddings_hand_labeled,'embeddings/initial_inputs/embeddings_hand_labeled.pickle')# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm_non_hand_labeled.to_csv('csv/tpm_non_hand_labeled.csv')\n",
    "tpm_hand_labeled.to_csv('csv/tpm_hand_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "tpm_hand_labeled['word_counts'] = tpm_hand_labeled['message'].str.split().apply(len)\n",
    "print(tpm_hand_labeled['word_counts'].max())\n",
    "\n",
    "tpm_non_hand_labeled['word_counts'] = tpm_non_hand_labeled['message'].str.split().apply(len)\n",
    "print(tpm_non_hand_labeled['word_counts'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n",
      "76889\n"
     ]
    }
   ],
   "source": [
    "print(len(tpm_hand_labeled))\n",
    "print(len(tpm_non_hand_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hand labeled IDs: 48\n",
      "Non-hand labeled IDs: 8436\n",
      "Number of common IDs: 0\n"
     ]
    }
   ],
   "source": [
    "hand_labeled_ids = tpm_hand_labeled['conversation_num'].unique() \n",
    "non_hand_labeled_ids = tpm_non_hand_labeled['conversation_num'].unique() \n",
    "\n",
    "print(\"Hand labeled IDs:\", len(hand_labeled_ids))\n",
    "print(\"Non-hand labeled IDs:\", len(non_hand_labeled_ids))\n",
    "\n",
    "# Convert lists to sets and find the intersection\n",
    "common_elements = set(hand_labeled_ids).intersection(set(non_hand_labeled_ids))\n",
    "\n",
    "# Get the number of similar elements\n",
    "number_of_similar_elements = len(common_elements)\n",
    "\n",
    "print(\"Number of common IDs:\", number_of_similar_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Featurization for ../sandbox/csv/tpm_hand_labeled.csv ...\n",
      "Confirmed that data has `conversation_num`, `message`, and `speaker_nickname` columns!\n",
      "Chat Level Features ...\n",
      "Generating features for the first 100.0% of messages...\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../team-process-map/feature_engine')\n",
    "from feature_builder import FeatureBuilder\n",
    "\n",
    "feature_builder_hand_labeled = FeatureBuilder(\n",
    "    input_file_path = '../sandbox/csv/tpm_hand_labeled.csv',\n",
    "    vector_directory = \"feature_engine_outputs/vector_data/\",\n",
    "    output_file_path_chat_level = \"../sandbox/csv/tpm_hand_labeled_chat_features.csv\",\n",
    "    output_file_path_user_level = \"../sandbox/csv/tpm_hand_labeled_user_labeled.csv\",\n",
    "    output_file_path_conv_level = \"../sandbox/csv/tpm_hand_labeled_conv_labeled.csv\",\n",
    "    turns = False,\n",
    ")\n",
    "\n",
    "feature_builder_hand_labeled.featurize(col='text')\n",
    "tpm_hand_labeled = pickle_embeddings(pd.read_csv(\"../sandbox/csv/tpm_hand_labeled_chat_features.csv\"),\"../sandbox/embeddings/initial_inputs/tpm_hand_labeled.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Featurization for ../sandbox/csv/tpm_non_hand_labeled.csv ...\n",
      "Confirmed that data has `conversation_num`, `message`, and `speaker_nickname` columns!\n",
      "Chat Level Features ...\n",
      "Generating features for the first 100.0% of messages...\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "#Generate TPM features and pickle\n",
    "feature_builder_non_hand_labeled = FeatureBuilder(\n",
    "    input_file_path = \"../sandbox/csv/tpm_non_hand_labeled.csv\",\n",
    "    vector_directory = \"feature_engine_outputs/vector_data/\",\n",
    "    output_file_path_chat_level = \"../sandbox/csv/tpm_non_hand_labeled_chat_features.csv\",\n",
    "    output_file_path_user_level = \"../sandbox/csv/tpm_non_hand_labeled_user_labeled.csv\",\n",
    "    output_file_path_conv_level = \"../sandbox/csv/tpm_non_hand_labeled_conv_labeled.csv\",\n",
    "    turns = False,\n",
    ")\n",
    "\n",
    "feature_builder_non_hand_labeled.featurize(col='text')\n",
    "tpm_hand_labeled = pickle_embeddings(pd.read_csv(\"../sandbox/csv/tpm_non_hand_labeled_chat_features.csv\"),\"../sandbox/embeddings/initial_inputs/tpm_non_hand_labeled.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
